#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°† HSK Excel æ–‡ä»¶è½¬æ¢ä¸ºæ ‡å‡† CSV æ ¼å¼
- ç®€ä½“è½¬ç¹ä½“
- æå–è¯è¯­å’Œç­‰çº§
- ç”Ÿæˆæ ‡å‡† CSVï¼šè¯è¯­,ç¬¬äºŒå±‚çº§,ç¬¬ä¸‰å±‚çº§
"""

import sys
import os
import re
import csv

# å°è¯•å¯¼å…¥ xlrdï¼ˆç”¨äºè¯»å– .xls æ–‡ä»¶ï¼‰
try:
    import xlrd
except ImportError:
    print("éœ€è¦å®‰è£… xlrd åº“")
    print("è¯·è¿è¡Œ: pip3 install xlrd")
    sys.exit(1)

# å°è¯•å¯¼å…¥ OpenCCï¼ˆç”¨äºç®€ç¹è½¬æ¢ï¼‰
try:
    from opencc import OpenCC
    cc = OpenCC('s2t')  # ç®€ä½“åˆ°ç¹ä½“
except ImportError:
    print("éœ€è¦å®‰è£… opencc-python-reimplemented åº“è¿›è¡Œç®€ç¹è½¬æ¢")
    print("è¯·è¿è¡Œ: pip3 install opencc-python-reimplemented")
    sys.exit(1)

# Excel æ–‡ä»¶è·¯å¾„
excel_file = '../docs/HSK-2012 (1).xls'
output_file = '../docs/hsk_standard_traditional.csv'

if not os.path.exists(excel_file):
    print(f"æ–‡ä»¶ä¸å­˜åœ¨: {excel_file}")
    sys.exit(1)

print("=" * 60)
print("ğŸš€ å¼€å§‹è½¬æ¢ HSK Excel æ–‡ä»¶")
print("=" * 60)

# æ‰“å¼€ Excel æ–‡ä»¶
workbook = xlrd.open_workbook(excel_file)

# ç­‰çº§æ˜ å°„ï¼ˆå·¥ä½œè¡¨å -> ç­‰çº§æ ‡ç­¾ï¼‰
level_mapping = {
    'HSKï¼ˆä¸€çº§ï¼‰ï¼ˆ150ï¼‰': 'HSK1ç´š',
    'HSKï¼ˆäºŒçº§ï¼‰ï¼ˆ300ï¼‰': 'HSK2ç´š',
    'HSKï¼ˆä¸‰çº§ï¼‰ï¼ˆ600ï¼‰': 'HSK3ç´š',
    'æ–°HSKï¼ˆå››çº§ï¼‰ï¼ˆ1200ï¼‰': 'HSK4ç´š',
    'æ–°HSKï¼ˆäº”çº§ï¼‰ï¼ˆ2500ï¼‰': 'HSK5ç´š',
    'æ–°HSKï¼ˆå…­çº§ï¼‰ï¼ˆ5000ï¼‰': 'HSK6ç´š'
}

# æ”¶é›†æ‰€æœ‰è¯æ±‡
all_words = []
stats = {}

print("\nğŸ“– æ­£åœ¨è¯»å–å„ç­‰çº§è¯æ±‡...\n")

for sheet_name, level_label in level_mapping.items():
    try:
        sheet = workbook.sheet_by_name(sheet_name)
        count = 0
        
        print(f"  å¤„ç†: {sheet_name} -> {level_label}")
        
        for row_idx in range(sheet.nrows):
            cell_value = str(sheet.cell(row_idx, 0).value).strip()
            
            if not cell_value:
                continue
            
            # æå–è¯è¯­ï¼ˆå»æ‰æ‹¬å·åŠå…¶å†…å®¹ï¼‰
            # ä¾‹å¦‚ï¼š"çˆ±ï¼ˆä¸€çº§ï¼‰" -> "çˆ±"
            word = re.sub(r'[ï¼ˆ(].*?[ï¼‰)]', '', cell_value).strip()
            
            if word:
                # ç®€ä½“è½¬ç¹ä½“
                word_traditional = cc.convert(word)
                
                all_words.append({
                    'word': word_traditional,
                    'level_2': level_label,
                    'level_3': ''
                })
                count += 1
        
        stats[level_label] = count
        print(f"    âœ… æå– {count} ä¸ªè¯æ±‡")
        
    except Exception as e:
        print(f"    âŒ å¤„ç†å¤±è´¥: {e}")

print(f"\nğŸ“Š ç»Ÿè®¡:")
print(f"  æ€»è®¡: {len(all_words)} ä¸ªè¯æ±‡")
for level, count in stats.items():
    print(f"  {level}: {count} ä¸ª")

# å»é‡ï¼ˆä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°çš„ç­‰çº§ï¼‰
seen = {}
unique_words = []

for item in all_words:
    word = item['word']
    if word not in seen:
        seen[word] = True
        unique_words.append(item)

print(f"\nå»é‡å: {len(unique_words)} ä¸ªå”¯ä¸€è¯æ±‡")

# å†™å…¥ CSV
print(f"\nğŸ’¾ å†™å…¥ CSV æ–‡ä»¶: {output_file}")

with open(output_file, 'w', newline='', encoding='utf-8') as f:
    writer = csv.writer(f)
    
    # å†™å…¥è¡¨å¤´
    writer.writerow(['è¯è¯­', 'ç¬¬äºŒå±‚çº§', 'ç¬¬ä¸‰å±‚çº§'])
    
    # å†™å…¥æ•°æ®
    for item in unique_words:
        writer.writerow([item['word'], item['level_2'], item['level_3']])

print("âœ… è½¬æ¢å®Œæˆï¼")
print("=" * 60)
print(f"\nğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_file}")
print(f"ğŸ“ˆ è¯æ±‡æ•°é‡: {len(unique_words)}")
print("\nå¯ä»¥ä½¿ç”¨æ­¤æ–‡ä»¶å¯¼å…¥åˆ°ç³»ç»Ÿè¯è¡¨äº†ï¼")
print("=" * 60)

# æ˜¾ç¤ºå‰ 10 ä¸ªè¯æ±‡ä½œä¸ºç¤ºä¾‹
print("\nğŸ“‹ å‰ 10 ä¸ªè¯æ±‡é¢„è§ˆ:")
print("-" * 60)
for i, item in enumerate(unique_words[:10], 1):
    print(f"{i:2d}. {item['word']:10s} | {item['level_2']}")
print("-" * 60)

