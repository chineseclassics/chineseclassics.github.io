<script setup>
/**
 * éŒ„éŸ³é¢æ¿çµ„ä»¶
 * åŒ…å«éŒ„éŸ³æŒ‰éˆ•ã€è¨ˆæ™‚å™¨ã€æ³¢å½¢ç·¨è¼¯ï¼ˆå«å‰ªè¼¯æ‹–å‹•æ¨™è¨˜ï¼‰ã€å‘½åå’Œä¸Šå‚³
 */
import { ref, computed, onMounted, onUnmounted, watch, nextTick } from 'vue'
import { useEditorStore, MIN_TRIM_DURATION } from '../../stores/editor'
import { useRecording } from '../../composables/useRecording'
import TravelerRecordings from './TravelerRecordings.vue'
import WaveSurfer from 'wavesurfer.js'

const store = useEditorStore()

const {
  isRecording,
  isSupported,
  formattedTime,
  formattedMaxTime,
  hasRecording,
  recordingUrl,
  recordingBlob,
  recordingDuration,
  recordingMimeType,
  isUploading,
  uploadError,
  locationName,
  isGettingLocation,
  checkSupport,
  startRecording,
  stopRecording,
  uploadRecording,
  getCurrentLocation,
  reset: resetRecording,
} = useRecording()

const emit = defineEmits(['recording-added'])

// æ³¢å½¢åœ–
const waveformContainer = ref(null)
const waveformWrapper = ref(null)
const trimHandleStart = ref(null)
const trimHandleEnd = ref(null)
const trimSelection = ref(null)
let wavesurfer = null

// å‰ªè¼¯ç¯„åœï¼ˆç§’ï¼‰
const trimStart = ref(0)
const trimEnd = ref(0)
const totalDuration = ref(0)

// æ‹–å‹•ç‹€æ…‹
let isDragging = null
let previewDebounceTimer = null
let previewTimeout = null
let previewTimeUpdateHandler = null

// éŒ„éŸ³åç¨±è¼¸å…¥
const nameInput = ref('')
const showNamePanel = ref(false)
const statusMessage = ref('')
const statusType = ref('') // 'error' | 'success' | ''

// è¨ˆç®—å±¬æ€§
const canSave = computed(() => {
  return nameInput.value.trim() && hasRecording.value && !isUploading.value
})

const selectedDuration = computed(() => {
  return Math.max(0, trimEnd.value - trimStart.value)
})

const formattedSelectedTime = computed(() => {
  return formatTime(selectedDuration.value)
})

const formattedTotalTime = computed(() => {
  return formatTime(totalDuration.value)
})

const locationButtonText = computed(() => {
  if (isGettingLocation.value) return 'ğŸ“ æ­£åœ¨ç²å–åœ°é»...'
  if (locationName.value) return `âœ“ ${locationName.value}`
  return 'ğŸ“ æ·»åŠ åœ°é»ä¿¡æ¯'
})

// æ ¼å¼åŒ–æ™‚é–“
function formatTime(seconds) {
  const mins = Math.floor(seconds / 60)
  const secs = Math.floor(seconds % 60)
  return `${mins}:${secs.toString().padStart(2, '0')}`
}

// åˆå§‹åŒ–
onMounted(() => {
  checkSupport()
  // ç¶å®šå…¨å±€æ‹–å‹•äº‹ä»¶
  document.addEventListener('mousemove', onDrag)
  document.addEventListener('mouseup', endDrag)
  document.addEventListener('touchmove', onTouchDrag, { passive: false })
  document.addEventListener('touchend', endDrag)
})

onUnmounted(() => {
  document.removeEventListener('mousemove', onDrag)
  document.removeEventListener('mouseup', endDrag)
  document.removeEventListener('touchmove', onTouchDrag)
  document.removeEventListener('touchend', endDrag)
  destroyWaveform()
})

// ç›£è½éŒ„éŸ³ URL è®ŠåŒ–ï¼Œåˆå§‹åŒ–æ³¢å½¢åœ–
watch(recordingUrl, async (url) => {
  if (url) {
    showNamePanel.value = true
    statusMessage.value = 'éŒ„éŸ³å®Œæˆï¼Œè«‹èª¿æ•´å‰ªåˆ‡ç¯„åœå¾Œå‘½åä¿å­˜ã€‚'
    statusType.value = ''
    await nextTick()
    await initWaveform(url)
  } else {
    showNamePanel.value = false
    destroyWaveform()
  }
})

// åˆå§‹åŒ–æ³¢å½¢åœ–
async function initWaveform(url) {
  if (!waveformContainer.value) return

  destroyWaveform()

  try {
    wavesurfer = WaveSurfer.create({
      container: waveformContainer.value,
      waveColor: getComputedStyle(document.documentElement).getPropertyValue('--color-text-tertiary').trim() || '#7a8574',
      progressColor: getComputedStyle(document.documentElement).getPropertyValue('--color-primary').trim() || '#789262',
      cursorColor: getComputedStyle(document.documentElement).getPropertyValue('--color-primary').trim() || '#789262',
      barWidth: 2,
      barRadius: 1,
      barGap: 1,
      height: 80,
      normalize: true,
      interact: true,
      backend: 'WebAudio',
      mediaControls: false,
    })

    await wavesurfer.load(url)

    totalDuration.value = wavesurfer.getDuration()
    trimStart.value = 0
    trimEnd.value = totalDuration.value

    // é»æ“Šæ³¢å½¢åœ–æ’­æ”¾é¸ä¸­å€åŸŸé è¦½
    wavesurfer.on('click', () => {
      if (wavesurfer.isPlaying()) {
        wavesurfer.pause()
      } else {
        playTrimmedPreview()
      }
    })

    // æ›´æ–°æ‹–å‹•æ¨™è¨˜ä½ç½®
    updateHandles()

    // å‹•ç•«æç¤º
    if (trimHandleStart.value && trimHandleEnd.value) {
      trimHandleStart.value.classList.add('animate-hint')
      trimHandleEnd.value.classList.add('animate-hint')
      setTimeout(() => {
        trimHandleStart.value?.classList.remove('animate-hint')
        trimHandleEnd.value?.classList.remove('animate-hint')
      }, 3500)
    }
  } catch (error) {
    console.error('åˆå§‹åŒ–æ³¢å½¢åœ–å¤±æ•—:', error)
    statusMessage.value = 'æ³¢å½¢åœ–è¼‰å…¥å¤±æ•—ï¼Œä½†éŒ„éŸ³å·²ä¿å­˜ã€‚'
    statusType.value = 'error'
  }
}

// éŠ·æ¯€æ³¢å½¢åœ–
function destroyWaveform() {
  if (previewDebounceTimer) {
    clearTimeout(previewDebounceTimer)
    previewDebounceTimer = null
  }
  if (previewTimeout) {
    clearTimeout(previewTimeout)
    previewTimeout = null
  }
  if (previewTimeUpdateHandler && wavesurfer) {
    try {
      wavesurfer.un('timeupdate', previewTimeUpdateHandler)
    } catch (e) {}
    previewTimeUpdateHandler = null
  }
  if (wavesurfer) {
    try {
      if (wavesurfer.isPlaying()) {
        wavesurfer.pause()
      }
      wavesurfer.destroy()
    } catch (e) {}
    wavesurfer = null
  }
}

// æ›´æ–°æ‹–å‹•æ¨™è¨˜ä½ç½®
function updateHandles() {
  if (!waveformWrapper.value || !trimHandleStart.value || !trimHandleEnd.value || !trimSelection.value) return
  if (totalDuration.value <= 0) return

  const startPercent = (trimStart.value / totalDuration.value) * 100
  const endPercent = (trimEnd.value / totalDuration.value) * 100

  trimHandleStart.value.style.left = `${startPercent}%`
  trimHandleEnd.value.style.left = `${endPercent}%`
  trimSelection.value.style.left = `${startPercent}%`
  trimSelection.value.style.width = `${endPercent - startPercent}%`
}

// é–‹å§‹æ‹–å‹•
function startDrag(handle, event) {
  event.preventDefault()
  isDragging = handle
  if (handle === 'start') {
    trimHandleStart.value?.classList.add('dragging')
  } else {
    trimHandleEnd.value?.classList.add('dragging')
  }
}

// æ‹–å‹•ä¸­
function onDrag(event) {
  if (!isDragging || !waveformWrapper.value) return

  const wrapperRect = waveformWrapper.value.getBoundingClientRect()
  const x = event.clientX - wrapperRect.left
  const percent = Math.max(0, Math.min(100, (x / wrapperRect.width) * 100))
  const newTime = (percent / 100) * totalDuration.value

  if (isDragging === 'start') {
    const maxTime = trimEnd.value - MIN_TRIM_DURATION
    trimStart.value = Math.max(0, Math.min(maxTime, newTime))
  } else if (isDragging === 'end') {
    const minTime = trimStart.value + MIN_TRIM_DURATION
    trimEnd.value = Math.min(totalDuration.value, Math.max(minTime, newTime))
  }

  updateHandles()
}

// è§¸æ‘¸æ‹–å‹•
function onTouchDrag(event) {
  if (!isDragging || event.touches.length === 0) return
  event.preventDefault()
  const touch = event.touches[0]
  onDrag({ clientX: touch.clientX })
}

// çµæŸæ‹–å‹•
function endDrag() {
  if (isDragging) {
    trimHandleStart.value?.classList.remove('dragging')
    trimHandleEnd.value?.classList.remove('dragging')

    // æ‹–å‹•çµæŸå¾Œé è¦½
    if (previewDebounceTimer) {
      clearTimeout(previewDebounceTimer)
    }
    previewDebounceTimer = setTimeout(() => {
      playTrimmedPreview()
    }, 300)
  }
  isDragging = null
}

// æ’­æ”¾å‰ªåˆ‡å¾Œçš„é è¦½
async function playTrimmedPreview() {
  if (!wavesurfer || !recordingBlob.value) return

  const startTime = trimStart.value
  const endTime = trimEnd.value

  // æ¸…é™¤ä¹‹å‰çš„æ’­æ”¾
  if (wavesurfer.isPlaying()) {
    wavesurfer.pause()
  }
  if (previewTimeout) {
    clearTimeout(previewTimeout)
    previewTimeout = null
  }
  if (previewTimeUpdateHandler) {
    wavesurfer.un('timeupdate', previewTimeUpdateHandler)
    previewTimeUpdateHandler = null
  }

  // è¨­ç½®æ’­æ”¾ä½ç½®
  wavesurfer.seekTo(startTime / totalDuration.value)

  try {
    await wavesurfer.play()

    const duration = endTime - startTime

    // ç›£è½æ™‚é–“æ›´æ–°ï¼Œåˆ°é”çµæŸé»æ™‚åœæ­¢
    previewTimeUpdateHandler = () => {
      const currentTime = wavesurfer.getCurrentTime()
      if (currentTime >= endTime) {
        wavesurfer.pause()
        if (previewTimeUpdateHandler) {
          wavesurfer.un('timeupdate', previewTimeUpdateHandler)
          previewTimeUpdateHandler = null
        }
        if (previewTimeout) {
          clearTimeout(previewTimeout)
          previewTimeout = null
        }
      }
    }
    wavesurfer.on('timeupdate', previewTimeUpdateHandler)

    // å‚™ä»½ timeout
    previewTimeout = setTimeout(() => {
      if (wavesurfer && wavesurfer.isPlaying()) {
        wavesurfer.pause()
      }
      if (previewTimeUpdateHandler) {
        wavesurfer.un('timeupdate', previewTimeUpdateHandler)
        previewTimeUpdateHandler = null
      }
      previewTimeout = null
    }, (duration + 0.2) * 1000)
  } catch (error) {
    console.error('æ’­æ”¾é è¦½å¤±æ•—:', error)
  }
}

// è™•ç†éŒ„éŸ³æŒ‰éˆ•é»æ“Š
async function handleRecordingToggle() {
  if (isRecording.value) {
    stopRecording()
  } else {
    statusMessage.value = 'éŒ„éŸ³ä¸­...'
    statusType.value = ''
    await startRecording()
  }
}

// éŸ³é »å‰ªè¼¯åŠŸèƒ½
async function trimAudio(blob, startTime, endTime) {
  if (!blob || startTime < 0 || endTime <= startTime) {
    return blob
  }

  try {
    const audioContext = new (window.AudioContext || window.webkitAudioContext)()
    const arrayBuffer = await blob.arrayBuffer()
    const audioBuffer = await audioContext.decodeAudioData(arrayBuffer)

    const sampleRate = audioBuffer.sampleRate
    const startSample = Math.floor(startTime * sampleRate)
    const endSample = Math.floor(endTime * sampleRate)
    const length = endSample - startSample

    const trimmedBuffer = audioContext.createBuffer(
      audioBuffer.numberOfChannels,
      length,
      sampleRate
    )

    for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
      const channelData = audioBuffer.getChannelData(channel)
      const trimmedData = trimmedBuffer.getChannelData(channel)
      for (let i = 0; i < length; i++) {
        trimmedData[i] = channelData[startSample + i]
      }
    }

    // è½‰æ›ç‚º WAV
    const wavBlob = audioBufferToWav(trimmedBuffer)
    await audioContext.close()

    return wavBlob
  } catch (error) {
    console.error('å‰ªè¼¯éŸ³é »å¤±æ•—:', error)
    return blob
  }
}

// AudioBuffer è½‰ WAV
function audioBufferToWav(buffer) {
  const length = buffer.length
  const numberOfChannels = buffer.numberOfChannels
  const sampleRate = buffer.sampleRate
  const arrayBuffer = new ArrayBuffer(44 + length * numberOfChannels * 2)
  const view = new DataView(arrayBuffer)

  const writeString = (offset, string) => {
    for (let i = 0; i < string.length; i++) {
      view.setUint8(offset + i, string.charCodeAt(i))
    }
  }

  writeString(0, 'RIFF')
  view.setUint32(4, 36 + length * numberOfChannels * 2, true)
  writeString(8, 'WAVE')
  writeString(12, 'fmt ')
  view.setUint32(16, 16, true)
  view.setUint16(20, 1, true)
  view.setUint16(22, numberOfChannels, true)
  view.setUint32(24, sampleRate, true)
  view.setUint32(28, sampleRate * numberOfChannels * 2, true)
  view.setUint16(32, numberOfChannels * 2, true)
  view.setUint16(34, 16, true)
  writeString(36, 'data')
  view.setUint32(40, length * numberOfChannels * 2, true)

  let offset = 44
  for (let i = 0; i < length; i++) {
    for (let channel = 0; channel < numberOfChannels; channel++) {
      const sample = Math.max(-1, Math.min(1, buffer.getChannelData(channel)[i]))
      view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7fff, true)
      offset += 2
    }
  }

  return new Blob([arrayBuffer], { type: 'audio/wav' })
}

// ä¿å­˜éŒ„éŸ³
async function handleSave() {
  if (!canSave.value) return

  try {
    statusMessage.value = 'éŒ„éŸ³ä¸Šå‚³ä¸­...'
    statusType.value = ''

    // å¦‚æœæœ‰å‰ªè¼¯ï¼Œå…ˆå‰ªè¼¯éŸ³é »
    let blobToUpload = null
    if (trimStart.value > 0 || trimEnd.value < totalDuration.value) {
      blobToUpload = await trimAudio(recordingBlob.value, trimStart.value, trimEnd.value)
    }

    const result = await uploadRecording(nameInput.value.trim(), blobToUpload)

    // å°‡éŒ„éŸ³æ·»åŠ åˆ°å·²é¸éŸ³æ•ˆ
    store.toggleSoundSelection({
      id: result.id,
      name: result.display_name,
      file_url: result.file_url,
      sourceType: 'recording',
      recordingPath: result.storage_path,
      recordingId: result.id,
      ownerId: result.owner_id,
      recordingStatus: result.status,
      locationName: result.location_name,
      tags: result.location_name ? [result.location_name, 'å¾…å¯©æ ¸'] : ['å¾…å¯©æ ¸'],
    })

    // é‡æ–°åŠ è¼‰æ—…äººéŒ„éŸ³åˆ—è¡¨
    await store.loadTravelerRecordings()

    // é‡ç½®éŒ„éŸ³ç‹€æ…‹
    handleCancel()

    statusMessage.value = 'éŒ„éŸ³å·²ä¿å­˜ä¸¦åŠ å…¥éŸ³æ•ˆæ¸…å–®ã€‚'
    statusType.value = 'success'

    emit('recording-added', result)
  } catch (error) {
    console.error('ä¿å­˜éŒ„éŸ³å¤±æ•—:', error)
    statusMessage.value = `éŒ„éŸ³ä¸Šå‚³å¤±æ•—ï¼š${error.message || 'è«‹ç¨å¾Œå†è©¦'}`
    statusType.value = 'error'
  }
}

// å–æ¶ˆéŒ„éŸ³
function handleCancel() {
  resetRecording()
  nameInput.value = ''
  showNamePanel.value = false
  trimStart.value = 0
  trimEnd.value = 0
  totalDuration.value = 0
  destroyWaveform()
  statusMessage.value = 'å·²å–æ¶ˆæœ¬æ¬¡éŒ„éŸ³ã€‚'
  statusType.value = ''
}
</script>

<template>
  <div class="editor-section" id="recording-section">
    <div class="recording-header">
      <span class="recording-label">æ—…äººéŒ„éŸ³</span>
      <span class="recording-subtext">å–®æ¬¡æœ€é•· 120 ç§’</span>
    </div>

    <!-- å·²ç™¼å¸ƒçš„æ—…äººéŒ„éŸ³ -->
    <TravelerRecordings />

    <!-- éŒ„éŸ³æ§åˆ¶ -->
    <div class="recording-inline">
      <button
        class="recording-toggle"
        :class="{ 'recording-active': isRecording }"
        id="recording-toggle-btn"
        type="button"
        :disabled="!isSupported || isUploading"
        :aria-label="isRecording ? 'åœæ­¢éŒ„éŸ³' : 'é–‹å§‹éŒ„éŸ³'"
        @click="handleRecordingToggle"
      >
        <i :class="isRecording ? 'fas fa-stop' : 'fas fa-circle'" aria-hidden="true"></i>
      </button>
      <div class="recording-timer-text" id="recording-timer">
        {{ formattedTime }} / {{ formattedMaxTime }}
      </div>
    </div>

    <!-- éŒ„éŸ³ç‹€æ…‹æç¤º -->
    <div class="recording-status" id="recording-status">
      <span v-if="!isSupported" class="recording-status-error">
        æ­¤è¨­å‚™æˆ–ç€è¦½å™¨ä¸æ”¯æ´éŒ„éŸ³åŠŸèƒ½
      </span>
      <span 
        v-else-if="statusMessage" 
        :class="{
          'recording-status-error': statusType === 'error',
          'recording-status-success': statusType === 'success'
        }"
      >
        {{ statusMessage }}
      </span>
    </div>

    <!-- éŒ„éŸ³å‘½åé¢æ¿ -->
    <div v-if="showNamePanel" class="recording-name-panel" id="recording-name-panel">
      <!-- æ³¢å½¢åœ–å®¹å™¨ -->
      <div class="recording-waveform-container">
        <div ref="waveformWrapper" class="recording-waveform-wrapper">
          <div ref="waveformContainer" id="recording-waveform" class="recording-waveform"></div>
          <!-- è‡ªå®šç¾©æ‹–å‹•æ¨™è¨˜ -->
          <div class="recording-trim-overlay">
            <div ref="trimSelection" class="recording-trim-selection" id="recording-trim-selection"></div>
            <div 
              ref="trimHandleStart" 
              class="recording-trim-handle recording-trim-handle-start" 
              id="recording-trim-handle-start"
              @mousedown="startDrag('start', $event)"
              @touchstart.prevent="startDrag('start', $event)"
            >
              <div class="recording-trim-handle-line"></div>
              <div class="recording-trim-handle-dot"></div>
            </div>
            <div 
              ref="trimHandleEnd" 
              class="recording-trim-handle recording-trim-handle-end" 
              id="recording-trim-handle-end"
              @mousedown="startDrag('end', $event)"
              @touchstart.prevent="startDrag('end', $event)"
            >
              <div class="recording-trim-handle-line"></div>
              <div class="recording-trim-handle-dot"></div>
            </div>
          </div>
        </div>
        <div class="recording-time-info">
          <span id="recording-selected-time">å·²é¸å– {{ formattedSelectedTime }}</span>
          <span class="recording-time-separator">/</span>
          <span id="recording-total-time">ç¸½é•·åº¦ {{ formattedTotalTime }}</span>
        </div>
      </div>

      <!-- å‘½åè¼¸å…¥ -->
      <label class="recording-name-label" for="recording-name-input">ç‚ºéŒ„éŸ³å‘½å</label>
      <div class="recording-name-input-group">
        <input
          v-model="nameInput"
          type="text"
          id="recording-name-input"
          class="editor-input"
          maxlength="50"
          placeholder="ä¾‹å¦‚ï¼šæ¾é¢¨å…¥å¤œ"
        />
        <button
          type="button"
          id="recording-location-btn"
          class="recording-location-btn"
          :class="{ 'has-location': locationName }"
          :disabled="isGettingLocation"
          aria-label="æ·»åŠ åœ°é»ä¿¡æ¯"
          @click="getCurrentLocation"
        >
          <span class="recording-location-btn-text">{{ locationButtonText }}</span>
        </button>
      </div>

      <!-- æ“ä½œæŒ‰éˆ• -->
      <div class="recording-name-actions">
        <button
          class="recording-action-primary"
          id="recording-save-btn"
          type="button"
          :disabled="!canSave"
          @click="handleSave"
        >
          ä¿å­˜éŒ„éŸ³
        </button>
        <button
          class="recording-action-secondary"
          id="recording-cancel-btn"
          type="button"
          @click="handleCancel"
        >
          å–æ¶ˆ
        </button>
      </div>
    </div>
  </div>
</template>

<style scoped>
/* ä½¿ç”¨å…¨å±€ atmosphere-editor.css æ¨£å¼ */
</style>
