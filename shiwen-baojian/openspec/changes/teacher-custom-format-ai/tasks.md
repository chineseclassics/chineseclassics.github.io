# 老师自定义格式 + AI 辅助生成 - 任务清单

> **系统重新定位**（2025-10-20）：
> - 原始定位：**论文格式宝典**（只关注格式规范）
> - 新定位：**智能写作辅导系统**（格式 + 内容要求）
> - 核心变化：从单纯的「格式检查」到「按老师要求写作」
> - UI 统一：使用「**写作要求**」（涵盖格式 + 内容）
> - 代码层：保持 `formatSpec` 等变量名（避免大规模重构）

## 📋 实施策略

**分 3 个会话完成，每个会话一个阶段。**

**总任务数**：81 个（78 个 MVP 必需 + 3 个可选）  
**阶段划分**：22 个 + 29 个 + 27 个 = 78 个（MVP 必需）

**划分原则**：
- 每个阶段 20-30 个任务（可管理的范围，单次会话可完成）
- 明确的交付物（可独立测试和验证）
- 清晰的依赖链（数据库 → AI → 界面 → 集成）
- 风险优先（先验证 AI 核心能力，再做用户界面，最后系统集成）

---

## 🏗️ 阶段 1：数据库 + AI 核心引擎

**目标**：AI 格式生成器可用，能够解析老师要求并生成 JSON  
**任务数**：22 个  
**会话**：第一次会话

**核心设计**：
- 两阶段流程（AI 生成文本 → 纯代码解析 JSON）
- 支持两种模式（增量 / 自定义）
- AI 职责边界（只做客观检查）
- 基于真实教学案例设计 Prompt

### 1.1 数据库准备

- [x] 1.1.1 创建 `016_create_grading_rubrics.sql` 迁移
- [x] 1.1.2 创建 `grading_rubrics` 表
- [x] 1.1.3 创建 `ai_grading_suggestions` 表
- [x] 1.1.4 在 Dashboard 执行迁移
- [x] 1.1.5 验证表结构和 RLS 策略

**注意**：不需要擴展 `format_specifications` 表，`constraints` 和 `content_requirements` 直接整合到 `spec_json` 中

### 1.2 评分标准数据准备

**基于真实教学案例**：IB MYP 中國古典文學評分標準（A/B/C/D 四個標準）

- [x] 1.2.1 创建 `assets/data/grading-rubrics/` 目录
- [x] 1.2.2 转换「中國古典文學」评分标准为 JSON 格式（已有文档）
- [x] 1.2.3 定义评分标准 JSON Schema（参考已有文档）
- [x] 1.2.4 创建评分标准加载器（`js/data/grading-rubric-loader.js`）
- [x] 1.2.5 测试评分标准加载和引用

### 1.3 AI 格式生成 Edge Function

**參考文檔**：`AI_PROMPT_DESIGN.md`
**實際實現**：兩階段流程（generate_readable + convert_to_json）

- [x] 1.3.1 創建 `supabase/functions/format-spec-generator/` 目錄
- [x] 1.3.2 實現 System Prompt（基於 AI_PROMPT_DESIGN.md，移除評分標準）
- [x] 1.3.3 實現 User Prompt Template
- [x] 1.3.4 整合 DeepSeek API 調用
- [x] 1.3.5 實現兩階段流程（階段1：AI生成文本，階段2：純代碼解析）
- [x] 1.3.6 實現純代碼解析函數（parseHumanReadableToJSON）
- [x] 1.3.7 實現字數/段落數提取邏輯
- [x] 1.3.8 實現內容要求轉換為 analysis_dimensions
- [x] 1.3.9 實現 JSON 驗證（寬鬆模式，自動補充缺失字段）
- [x] 1.3.10 添加錯誤處理
- [x] 1.3.11 部署 Edge Function（通過 Dashboard 手動部署）
- [x] 1.3.12 測試真實案例（春江花月夜結構分析）

**阶段 1 交付成果**：
- ✅ 数据库表结构完整（grading_rubrics, ai_grading_suggestions）
- ✅ 评分标准 JSON 数据准备完成
- ✅ AI Edge Function 部署并可用
- ✅ 两阶段流程创新（AI 生成文本 → 纯代码解析 JSON）
- ✅ 遵循 AI 职责边界（只客观检查，不主观判断）
- ✅ 可独立测试 AI 解析能力
- ✅ 性能提升 ~500 倍

---

## 🎨 阶段 2：统一 Quill 编辑器 + 格式管理

**目标**：完整的格式创建和管理界面  
**任务数**：29 个  
**会话**：第二次会话  
**前置条件**：✅ 阶段 1 已完成（AI Engine 可用）

### 2.1 老師端 - 統一 Quill 格式編輯器

**核心設計**：所有格式操作都在一個 Quill 編輯器中完成

- [x] 2.1.1 創建格式編輯器頁面 HTML（卡片式格式選擇 + Quill 編輯器）
- [x] 2.1.2 集成 Quill.js 純文本編輯器（toolbar: false）
- [x] 2.1.3 實現系統格式卡片組件（圖標、名稱、簡介、預覽按鈕）
- [x] 2.1.4 實現「從零開始」選項卡
- [x] 2.1.5 實現格式 JSON → 人類可讀轉換函數
- [x] 2.1.6 實現「加載預覽」功能（在 Quill 中顯示系統格式）
- [x] 2.1.7 監聽 Quill 內容變化（檢測用戶修改，切換模式）
- [x] 2.1.8 實現模式識別邏輯（direct / incremental / custom）
- [x] 2.1.9 實現「AI 優化」按鈕和狀態管理（hasBeenOptimized）
- [x] 2.1.10 實現 AI 優化請求（調用 format-spec-generator 兩階段流程）
- [x] 2.1.11 處理 AI 輸出（自動完成階段1+階段2）
- [x] 2.1.12 實現 JSON 緩存（cachedFormatJSON）
- [x] 2.1.13 實現「保存」按鈕邏輯（智能狀態管理）
- [x] 2.1.14 實現格式命名和描述輸入（保存對話框）
- [x] 2.1.15 實現保存邏輯（創建 + 更新，集成認證）
- [x] 2.1.16 測試三種模式的完整流程

### 2.2 老師端 - 自定義格式管理

- [x] 2.2.1 創建格式管理頁面（format-manager.html）
- [x] 2.2.2 實現格式列表展示（系統模板 + 自定義模板，從 Supabase 加載）
- [x] 2.2.3 實現格式卡片組件（名稱、描述、創建時間、類型標籤）
- [x] 2.2.4 實現格式詳情查看（模態框顯示）
- [x] 2.2.5 實現格式編輯功能（跳轉到編輯器，URL 參數 ?edit=id）
- [x] 2.2.6 實現格式刪除功能（Supabase SDK，確認對話框）
- [x] 2.2.7 系統內置格式不可刪除（UI 條件渲染，不顯示刪除按鈕）
- [x] 2.2.8 實現格式搜索和篩選（按類型、名稱，支持排序）
- [x] 2.2.9 測試格式管理功能（全流程測試成功）

**注意**：阶段 2 实现时假设快照模式，阶段 3 改为**引用模式**（老师修改格式会影响正在写作的学生）

### 2.3 格式復制功能（MVP：直接復制）

**注意**：MVP 階段不做導出功能，老師可直接從 Quill 編輯器複製內容

- [x] 2.3.1 在格式詳情模態框添加「複製格式說明」按鈕
- [x] 2.3.2 實現一鍵複製到剪貼板功能（navigator.clipboard API）
- [x] 2.3.3 複製成功提示（alert）
- [x] 2.3.4 測試複製到 Word/記事本等應用

**第二階段（可選）**：
- [ ] 2.3.5 引入 `docx.js` 庫
- [ ] 2.3.6 實現導出為 Word (.docx) 格式
- [ ] 2.3.7 實現導出為 PDF 格式

**阶段 2 交付成果**：
- ✅ 老师能在统一的 Quill 编辑器中创建格式（format-editor.html）
- ✅ 三种模式完整可用（Direct / Incremental / Custom）
- ✅ AI 两阶段优化（生成文本 + 纯代码解析，性能提升 500 倍）
- ✅ 格式管理功能完整（format-manager.html）
- ✅ 完整 CRUD：创建、查看、编辑、删除、搜索、筛选
- ✅ 老师可以复制格式说明分享给学生（一键复制）
- ✅ 自定义格式保存到数据库（Supabase 集成，RLS 策略保护）
- ✅ 认证系统集成（SessionManager，显示用户信息）
- ✅ 移除评分标准（格式要求与评分标准完全分离）

---

## 🔗 阶段 3：任务集成 + AI 评分系统

**目标**：完全集成到现有系统，老师可使用自定义格式创建任务并获得 AI 评分建议  
**任务数**：25 个  
**会话**：第三次会话  
**前置条件**：✅ 阶段 2 已完成（格式创建和管理）

### 3.1 任务创建集成 + 学生端格式显示

**核心设计决策**（2025-10-20 最终确认）：
- ✅ **引用模式**：保存 format_spec_id（而非 JSON 快照）
- ✅ **移除任务描述**：只保留写作要求，避免混淆
- ✅ **自然语言显示**：学生看到 AI 优化后的结构化文本（human_input）
- ✅ **实时生效**：老师修改写作要求后，学生立即看到最新内容
- ✅ **概念重新定位**：UI 统一使用「写作要求」（而非「格式」）

- [x] 3.1.1 数据库结构调整（引用模式 + human_input）
  - ✅ 创建迁移：`017_add_human_input_and_reference_mode.sql`
  - ✅ 添加 `format_specifications.human_input TEXT`（AI 优化后的结构化文本）
  - ✅ 修改 `assignments` 表：
    - 添加 `format_spec_id UUID REFERENCES format_specifications(id)`
    - 移除 `description TEXT`（不再需要任务说明字段）
    - 移除 `format_spec_json JSONB`（改用引用）
  - ⚠️ **需要手动操作**：在 Supabase Dashboard SQL Editor 执行迁移

- [x] 3.1.2 为系统格式添加 human_input
  - ✅ 为「红楼梦论文格式」编写自然语言描述
  - ✅ 包含：总体要求、结构要求（引言/正文/结论）、引用要求、语言要求、写作提示
  - ✅ 创建迁移：`018_add_honglou_format_human_input.sql`
  - ⚠️ **需要手动操作**：在 Supabase Dashboard SQL Editor 执行更新

- [x] 3.1.3 修改格式编辑器（保存 human_input）
  - ✅ 修改 `js/teacher/format-editor.js`
  - ✅ 保存时同时保存：
    - `human_input`：Quill 编辑器的纯文本内容（getText()）
    - `spec_json`：AI 生成的 JSON（cachedFormatJSON）
  - ✅ 使用 `quill.getText().trim()` 获取 AI 优化后的文本
  - ✅ 模式 A/B/C 都会保存 human_input（学生端显示用）

- [x] 3.1.4 统一 UI 文字为「写作要求」（概念重新定位）
  - ✅ 修改 `format-editor.html`：
    - 页面标题：「寫作要求編輯器」
    - 导航链接：「我的寫作要求」
    - 编辑器标题：「寫作要求編輯器」
    - 系统列表：「系統寫作要求列表」
    - 保存按钮：「保存寫作要求」
    - 保存对话框：「保存寫作要求」、「寫作要求名稱」
    - AI 处理提示：「AI 正在優化寫作要求...」
  - ✅ 修改 `format-manager.html`：
    - 页面标题：「寫作要求管理」
    - 主标题：「我的寫作要求」
    - 创建按钮：「創建新寫作要求」
    - 搜索框：「搜索寫作要求名稱或描述...」
    - 列表注释：「寫作要求列表」
    - 空状态：「還沒有自定義寫作要求」
    - 详情标题：「寫作要求詳情」
    - 删除提示：「確定要刪除這個寫作要求嗎？」
  - ⚠️ 注意：代码变量名保持不变（formatSpec、formatData 等）

- [x] 3.1.5 修改任务创建页面（移除描述，使用引用）
  - ✅ 修改 `js/teacher/assignment-creator.js`：
    - 移除「任务描述」输入框（60-73行）
    - 添加 `selectedTemplateId` 属性保存格式ID
    - `handleTemplateChange()` 中保存 templateId
    - `handleSubmit()` 中使用 `formatSpecId` 而非 `formatSpecJson`
    - 提示文字：「请选择写作要求」
  - ✅ 修改 `js/teacher/assignment-manager.js`：
    - `createAssignment()` 接收 `formatSpecId` 参数
    - 插入时使用 `format_spec_id` 字段（引用模式）
    - 移除 `description` 字段
    - `duplicateAssignment()` 复制 `format_spec_id`

- [x] 3.1.6 学生端：显示写作要求（自然语言）
  - ✅ 修改 `js/app.js:loadAssignmentData()`：
    - 关联查询 `format_specifications(id, name, human_input, spec_json)`
    - 在任务描述区域显示 `human_input`（自然语言）
    - 保存 `spec_json` 到 `AppState.currentFormatSpec`（供 AI 反馈使用）
    - 移除任务描述显示（字段已删除）

- [x] 3.1.7 学生端：传递格式规范给 AI 反馈
  - ✅ 修改 `js/student/essay-writer.js:requestParagraphFeedback()`：
    - 传递 `AppState.currentFormatSpec` 给 `requestAIFeedback()`
  - ✅ `js/ai/feedback-requester.js` 已支持 formatSpec 参数（阶段 1 完成）
  - ✅ 学生写作时，AI 反馈基于正确的格式规范

- [ ] 3.1.8 实现评分标准选择器（标准集单选 + 具体标准多选）
  - 下拉选择评分标准集（IB MYP 中国古典文学）
  - 复选框选择使用哪些标准（A/B/C/D，默认全选）
  - 至少选择 1 个标准（前端验证）
  - 过滤并保存选中的标准到 `grading_rubric_json`

- [ ] 3.1.9 测试任务创建和写作要求显示流程
  - 老师创建任务（模式 A：系统写作要求）
  - 老师创建任务（模式 B/C：自定义写作要求）
  - 学生端查看写作要求（验证显示自然语言）
  - 老师修改写作要求，学生刷新后看到更新
  - 学生写作时 AI 反馈使用正确的格式规范

### 3.2 AI 评分代理 Edge Function

**部署方式**：⚠️ **只能通过 Dashboard 手动部署**（避免与 story-vocab 项目冲突）

- [ ] 3.2.1 创建 `supabase/functions/grading-agent/` 目录
- [ ] 3.2.2 实现 Edge Function 基础结构（index.ts）
  - CORS 处理
  - 请求参数验证（essay_id, grading_rubric_json）
  - Supabase 客户端初始化

- [ ] 3.2.3 实现学生论文内容提取
  - 查询 essays 表（获取完整论文）
  - 查询 paragraphs 表（获取所有段落）
  - 组装完整论文文本

- [ ] 3.2.4 实现评分标准 JSON 加载和验证
  - 解析 grading_rubric_json
  - 验证包含的标准（可能只有 A/C/D，没有 B）
  - 准备评分标准描述符

- [ ] 3.2.5 实现 DeepSeek API 调用（基于评分标准分析）
  - System Prompt：基于 IB 标准评分
  - User Prompt：论文内容 + 选定的评分标准
  - 遵循 AI 职责边界（只客观评分，不主观判断）

- [ ] 3.2.6 实现评分生成（仅选中的标准）
  - 只为选中的标准生成评分（如 A/C/D）
  - 未选中的标准设为 NULL（如 B）
  - 每个标准：0-8 分 + 理由

- [ ] 3.2.7 保存评分建议到数据库
  - 插入到 `ai_grading_suggestions` 表
  - 关联 essay_id 和 grading_rubric_id

- [ ] 3.2.8 配置环境变量
  - 复用现有的 `DEEPSEEK_API_KEY`
  - 验证环境变量存在

- [ ] 3.2.9 手动部署 Edge Function（⚠️ Dashboard 操作）
  1. 复制 `grading-agent/index.ts` 完整代码
  2. 打开 Supabase Dashboard → Edge Functions
  3. 创建新函数：`grading-agent`
  4. 粘贴代码
  5. 配置环境变量：DEEPSEEK_API_KEY
  6. 点击 Deploy
  7. 记录函数 URL

- [ ] 3.2.10 测试 Edge Function 完整流程
  - 使用测试论文调用函数
  - 验证返回四个标准的评分
  - 验证评分理由符合客观性要求
  - 验证保存到数据库成功

### 3.3 老师端 - AI 评分建议界面

**触发方式**：✅ **手动触发**（老师点击按钮）

- [ ] 3.3.1 在老师批改页面添加 AI 评分建议区域
  - 修改 `js/teacher/grading-ui.js`
  - 位置：在「作业内容」和「评分表单」之间
  - 按钮样式：次要按钮（btn-secondary）
  - 图标：fas fa-robot
  - 文案：「获取 AI 评分建议」

- [ ] 3.3.2 创建 AI 评分请求模块
  - 创建 `js/teacher/ai-grading-requester.js`
  - 调用 `grading-agent` Edge Function
  - 传递参数：essay_id, grading_rubric_json

- [ ] 3.3.3 实现加载状态动画
  - 显示：「AI 正在分析论文...」
  - 加载图标：旋转动画
  - 禁用按钮（防止重复点击）
  - 预计时间：3-15 秒

- [ ] 3.3.4 实现评分建议展示界面
  - 卡片布局：每个标准一个卡片
  - 只显示任务选中的标准（如只显示 A/C/D）
  - 未选中的标准不显示（如 B）

- [ ] 3.3.5 实现评分和理由显示
  - 每个标准显示：
    - 标准代码和名称（如「A - 分析」）
    - AI 建议分数（0-8 分，大号字体）
    - 评分理由（客观依据）
  - 总分计算（选中标准的总和）
  - 免责声明：「此为 AI 建议，仅供参考」

- [ ] 3.3.6 实现「采用建议」快捷按钮
  - 一键填充评分表单
  - 自动填充所有选中标准的分数
  - 老师仍可手动调整
  - 老师必须填写评语才能提交

- [ ] 3.3.7 测试 RLS 策略（学生不可见）
  - ✅ RLS 策略已在 016 迁移中定义
  - 测试学生登录查询 ai_grading_suggestions（应返回空）
  - 测试老师登录查询（应返回数据）
  - 验证策略正确工作

- [ ] 3.3.8 测试 AI 评分完整流程
  - 学生提交完整论文
  - 老师打开批改页面
  - 点击「获取 AI 评分建议」
  - 验证显示评分和理由
  - 点击「采用建议」自动填充
  - 手动调整分数
  - 提交最终评分
  - 学生查看（只看到老师评分，看不到 AI 建议）

**阶段 3 交付成果**：
- ✅ 引用模式：老师修改写作要求后，学生看到最新内容
- ✅ 移除任务描述字段：避免与写作要求混淆
- ✅ 学生看到自然语言：AI 优化后的结构化文本，易于理解
- ✅ 格式规范传递给 AI：学生写作时使用正确的格式反馈
- ✅ 评分标准多选：老师可选择使用部分标准（如只用 A/C/D）
- ✅ AI 评分建议：基于选定标准，只客观评分
- ✅ RLS 策略保护：学生不可见 AI 评分建议
- ✅ UI 文字统一：所有界面使用「写作要求」
- ✅ 系统完全集成，生产就绪

---

## 📊 总任务统计（2025-10-20 最终确认）

**阶段 1：数据库 + AI 核心引擎**
- 1.1 数据库准备：5 个任务
- 1.2 评分标准准备：5 个任务
- 1.3 AI Edge Function：12 个任务
- **小计：22 个任务** ✅ 已完成

**阶段 2：统一 Quill 编辑器 + 格式管理**
- 2.1 Quill 编辑器界面：16 个任务
- 2.2 格式管理：9 个任务
- 2.3 复制功能：4 个任务（MVP）
- **小计：29 个任务** ✅ 已完成

**阶段 3：任务集成 + AI 评分系统**（2025-10-20 调整）
- 3.1 任务创建集成 + 学生端显示：9 个任务
- 3.2 AI 评分 Edge Function：10 个任务
- 3.3 AI 评分 UI：8 个任务
- **小计：27 个任务** ⏳ 待实施

**总计：78 个任务**（MVP 必需）+ **3 个可选任务**（Word/PDF 导出）= **81 个任务**

**任务分布**：
- 阶段 1：22 个任务（28%）✅ 已完成
- 阶段 2：29 个任务（37%）✅ 已完成
- 阶段 3：27 个任务（35%）⏳ 待实施

**关键设计决策**（2025-10-20 最终确认）：
- ✅ **引用模式**：assignments.format_spec_id（实时生效）
- ✅ **human_input 字段**：保存 AI 优化后的结构化文本（学生端显示）
- ✅ **移除 description**：避免混淆任务说明和写作要求
- ✅ **概念重新定位**：「格式」→「写作要求」（涵盖格式 + 内容）
- ✅ **UI 文字统一**：所有界面使用「写作要求」（代码保持 formatSpec）
- ✅ **评分标准多选**：老师可选择使用部分标准（如只用 A/C/D）
- ✅ **手动触发 AI 评分**：按钮点击触发
- ✅ **手动部署 Edge Function**：Dashboard 复制粘贴

---

## 🎯 当前状态

**状态**：阶段 1-2 已完成，准备开始阶段 3  
**完成日期**：2025-10-19（阶段 1-2）  
**进度**：51/78 任务（65%）

**已完成**：
- ✅ 阶段 1：数据库 + AI 核心引擎（22/22 任务）
- ✅ 阶段 2：统一 Quill 编辑器 + 格式管理（29/29 任务）
- ⏳ 阶段 3：任务集成 + AI 评分系统（0/27 任务）

**阶段 3 设计方案已确认**（2025-10-20）：
- ✅ 引用模式 vs 快照模式 → 选择**引用模式**
- ✅ 任务描述 vs 写作要求 → **移除任务描述**
- ✅ JSON vs 自然语言 → 学生看到**自然语言**（AI 优化后的文本）
- ✅ 概念重新定位 → **「格式」→「写作要求」**（涵盖格式 + 内容）
- ✅ UI 文字统一 → 所有界面使用**「写作要求」**（代码保持 formatSpec）
- ✅ 评分标准选择 → **单选标准集 + 多选具体标准**
- ✅ AI 评分触发 → **手动触发**（按钮点击）

**依赖的已完成功能**：
- ✅ 任务管理系统（老师可创建任务）
- ✅ 批改系统（老师可批改论文）
- ✅ 格式规范表（`format_specifications` 已创建并执行迁移）
- ✅ AI 反馈引擎（`ai-feedback-agent` 已部署）

---

## 🔄 与现有系统的集成

### 依赖关系

```
shiwen-baojian-mvp (阶段 1-3) ✅ 已完成
    ↓
teacher-custom-format-ai (本变更)
    ↓ 依赖
    - format-specification-system（已创建 format_specifications 表）
    - teacher-assignment-management（任务创建系统）
    - teacher-grading（批改系统）
    - ai-feedback-agent（AI 反馈引擎）
```

### 数据流（2025-10-20 更新）

```
【写作要求创建流程】
老师进入写作要求编辑器
    ↓
选择系统写作要求预览 OR 从零开始
    ↓
在 Quill 中查看/编辑要求（自然语言）
    ↓ (如有修改)
点击「AI 优化」→ format-spec-generator Edge Function
    ↓
【两阶段流程】
    阶段 1：AI 生成结构化人类可读文本（3-5 秒）
    阶段 2：纯代码函数解析为 JSON（<10 毫秒）
    ↓
Edge Function 返回：human_readable + format_json
    ↓
Quill 显示 human_readable（AI 优化后的结构化文本）
    ↓
缓存 format_json 到前端
    ↓
老师确认后保存到 format_specifications 表：
    - human_input: Quill 中显示的文本（AI 优化后）
    - spec_json: 解析得到的 JSON

【任务创建流程】（引用模式）
老师创建任务
    ↓
输入任务标题（如「红楼梦人物分析论文」）
    ↓
选择写作要求（系统写作要求 OR 自定义写作要求）
    ↓
选择评分标准（IB MYP，可多选 A/B/C/D）
    ↓
保存到 assignments 表：
    - title: "红楼梦人物分析论文"
    - format_spec_id: UUID（引用写作要求）
    - grading_rubric_json: {...}（包含选中的标准）
    - 注意：不再有 description 和 format_spec_json 字段

【学生写作流程】
学生打开任务
    ↓
加载任务数据（关联 format_specifications）
    ↓
显示任务标题 + 可展开「写作要求」显示 human_input（自然语言）
    ↓
保存 spec_json 到 AppState.currentFormatSpec
    ↓
学生写作段落
    ↓
请求 AI 反馈 → ai-feedback-agent（传递 spec_json）
    ↓
AI 基于写作要求检查段落（格式 + 内容）

【老师批改流程】
学生提交论文
    ↓
老师打开批改页面
    ↓
点击「获取 AI 评分建议」
    ↓
调用 grading-agent（传递 essay_id + grading_rubric_json）
    ↓
AI 返回选中标准的评分（如 A/C/D，跳过 B）
    ↓
老师查看建议 → 采用或忽略 → 手动调整 → 提交最终评分
```

---

## 📝 注意事项（2025-10-20 更新）

### 概念演进：从「格式」到「写作要求」

**系统定位变化**：

| 维度 | 原始定位（格式宝典） | 新定位（智能写作辅导） |
|------|---------------------|----------------------|
| **关注点** | 格式规范（结构、字数） | 格式 + 内容要求 |
| **模式 A** | 标准论文格式 | 预设写作要求 |
| **模式 B/C** | 自定义格式 | 自定义写作要求（含具体主题） |
| **学生看到** | 格式检查清单 | 完整的写作要求 |
| **AI 反馈** | 格式是否正确 | 是否符合老师要求 |
| **UI 文字** | 「格式」 | 「写作要求」 ✨ |
| **代码层** | `formatSpec` | `formatSpec`（保持不变） |

**典型案例对比**：

```
【模式 A - 纯格式】
总字数：1500-2500 字
引言：150-200 字
正文：3-5 个分论点
结论：150-200 字
→ 这是格式规范 ✓

【模式 B/C - 格式 + 内容】
总字数：1800-2000 字（格式）
正文：3 个分论点（格式）
详细分析林黛玉和薛宝钗的外貌描写（内容要求！）
每个人物不少于 300 字（格式 + 内容）
→ 这是写作要求（格式 + 内容）✓
```

**结论**：使用「**写作要求**」更准确地反映系统实际功能。

---

### 技术关键点

1. **引用模式（而非快照）**
   - 任务创建时保存 `format_spec_id`（引用）
   - 老师修改格式后，学生看到最新要求
   - 实时生效，符合灵活教学需求
   - 数据库存储更小（UUID vs JSON）

2. **human_input 字段（核心设计）**
   - `format_specifications.human_input`：保存 AI 优化后的结构化文本
   - 学生端显示用（易于理解）
   - `spec_json`：AI 生成的 JSON（AI 反馈使用）
   - 模式 A：使用系统写作要求的预设自然语言
   - 模式 B/C：保存 AI 优化后的结构化文本（非原始输入）
   - ⚠️ 老师在 Quill 中确认的最终文本才保存

3. **移除任务描述字段**
   - 删除 `assignments.description`
   - 避免老师混淆"任务说明"和"写作要求"
   - 只保留一个概念：写作要求（涵盖格式 + 内容）

4. **两阶段流程**（性能优化创新）
   - **阶段 1**：AI 生成结构化人类可读文本（3-5 秒）
   - **阶段 2**：纯代码函数解析为 JSON（<10 毫秒）
   - Edge Function 一次调用完成两个阶段
   - 返回：human_readable（显示在 Quill，保存到 human_input）+ format_json（保存到 spec_json）
   - 性能提升：~500 倍（阶段 2 从 5 秒降至 5 毫秒）

5. **评分标准多选**
   - 单选评分标准集（IB MYP）
   - 多选具体标准（A/B/C/D，默认全选）
   - AI 评分只为选中的标准生成分数
   - 未选中的标准设为 NULL

6. **手动部署 Edge Function**
   - 时文宝鉴使用独立 Supabase 项目
   - 只能通过 Dashboard 手动部署
   - 避免与 story-vocab 项目冲突

### 用户体验关键点

1. **统一 Quill 界面**
   - 所有格式操作都在同一个编辑器中
   - 系统格式预览也显示在 Quill 中（人类可读）
   - 三种模式自然流转，无需跳转页面

2. **强制优化逻辑**
   - 模式 A（直接使用）：保存按钮始终可用
   - 模式 B/C（有修改）：必须 AI 优化后才能保存
   - 内容变化后自动禁用保存，提示优化

3. **AI 优化体验**
   - 加载动画：「AI 正在理解您的要求...」（3-5 秒）
   - 优化完成：Quill 内容更新为结构化版本
   - 理解总结：让老师确认 AI 的理解

4. **错误处理**
   - AI 解析失败：友好提示 + 允许重新编辑
   - 网络失败：提示并保留用户输入
   - JSON 缓存丢失：自动重新优化

---

## 🧪 测试场景（基于真实教学案例）

### 场景 1：模式 A - 直接使用系统格式

1. 老师进入格式编辑器
2. 选择「红楼梦论文格式」
3. 点击「加载预览」→ Quill 显示人类可读版本
4. 老师阅读确认：「很好，就用这个」
5. 点击「直接保存使用」
6. 在任务创建时选择此格式

**验证**：
- ✅ 不调用 AI（直接使用系统格式 JSON）
- ✅ 保存速度快（无需等待 AI）

---

### 场景 2：模式 B - 基于系统格式增量

1. 老师选择「红楼梦论文格式」并加载预览
2. 在 Quill 底部添加：
   ```
   总字数 1800-2000 字
   必须 3 个分论点
   详细分析林黛玉和薛宝钗的外貌描写
   ```
3. 点击「AI 优化」（3-5 秒）
4. Quill 显示优化后的结构化版本
5. 老师确认并保存为「张老师红楼梦人物分析 2025」
6. 创建任务时选择此格式
7. 学生收到 AI 反馈时包含「外貌描写分析」维度

**验证**：
- ✅ AI 正确识别增量要求
- ✅ 合并到系统格式
- ✅ 两阶段流程正常（阶段 1：生成文本 → 阶段 2：解析 JSON）
- ✅ 学生看到的是 AI 优化后的结构化文本

---

### 场景 3：模式 C - 完全自定义（极简任务）

**真实案例**：春江花月夜结构分析

1. 老师选择「从零开始」
2. 在 Quill 中输入：
   ```
   请从至少两个方面，写两段话（不需要开头结尾），
   分析《春江花月夜》结构安排的精妙之处。
   字数：400-600 字
   评分标准：B 理解
   ```
3. 点击「AI 优化」
4. AI 输出结构化版本（两段式，无完整论文结构）
5. 老师确认并保存
6. 创建任务时使用此格式
7. 学生写作时只需写两段分析（无需引言和结论）

**验证**：
- ✅ AI 识别这是精简任务
- ✅ 不强加完整论文结构
- ✅ 忠实于老师要求

---

### 场景 4：模式 C - 完全自定义（三段固定结构）

**真实案例**：鶯鶯傳人物分析短写

1. 老师输入三段结构要求
2. AI 优化并生成对应的检查点
3. 保存格式
4. 学生按照三段结构写作
5. AI 反馈检查每段是否符合要求

**验证**：
- ✅ AI 识别固定结构
- ✅ 生成对应的 required_elements

---

### 场景 5：AI 评分建议

1. 学生完成论文并提交
2. 老师打开批改页面
3. 点击「AI 评分建议」
4. 3-5 秒后看到四个标准的评分（A/B/C/D，各 0-8 分）
5. 显示评分理由（基于客观依据）
6. 老师参考后手动调整分数
7. 学生只能看到老师的最终评分

**验证**：
- ✅ AI 评分基于选定的评分标准
- ✅ 评分理由客观（不主观判断）
- ✅ 学生不可见 AI 建议

---

### 场景 6：格式复制分享

1. 老师查看自定义格式
2. 点击「复制格式说明」
3. 复制到剪贴板
4. 粘贴到 Word 或 Google Docs
5. 分享给学生或同事

**验证**：
- ✅ 复制内容格式正确
- ✅ 可在其他应用中使用

---

## 📝 实施总结（2025-10-19）

### ✅ 阶段 1-2 已完成

**完成时间**：2025-10-19  
**完成任务**：51/76（67%）  
**实施会话**：第一次会话

### 🎯 核心成果

#### 1. 两阶段流程创新 ⚡

**设计决策**：分离 AI 生成和 JSON 转换
- **阶段 1**：AI 生成结构化文本（3-5秒）
- **阶段 2**：纯代码解析转 JSON（<10ms）

**效果**：
- 性能提升：~500倍（阶段2从5秒降至5ms）
- 用户体验：老师先确认文本，再转换
- 成本降低：只调用一次 AI
- 可靠性：纯代码解析，100% 确定性

#### 2. 格式要求与评分标准分离 📋

**设计决策**：移除格式中的评分标准
- AI 不生成评分标准内容
- 老师在任务创建时单独勾选评分标准（A/B/C/D）
- 职责清晰，灵活性高

#### 3. 完整的格式管理系统 🎨

**已实现功能**：
- 格式编辑器（format-editor.html）
- 格式管理页面（format-manager.html）
- 完整 CRUD 操作
- 认证集成（SessionManager）
- RLS 策略保护

### 🔧 关键技术实现

**已创建文件**：
```
shiwen-baojian/
├── format-editor.html              # 格式编辑器
├── format-manager.html             # 格式管理
├── STAGE2_TESTING_GUIDE.md         # 测试指南
├── SUPABASE_CONFIG.md              # 配置文档
├── test-format-spec-generator.html # 测试页面
├── test-two-stage-flow.sh          # 测试脚本
├── css/
│   └── format-editor.css
├── js/
│   ├── data/
│   │   └── grading-rubric-loader.js
│   └── teacher/
│       ├── format-editor.js
│       └── format-manager.js
├── assets/data/grading-rubrics/
│   └── ib-myp-chinese-literature.json
└── supabase/
    ├── migrations/
    │   ├── 013_create_format_specifications_table.sql
    │   └── 016_create_grading_rubrics.sql
    └── functions/
        └── format-spec-generator/
            └── index.ts
```

### 🐛 已解决的问题

1. **AI 输出多余内容** ✅
   - 修改 System Prompt，移除【重要提示】部分

2. **RLS 策略拒绝保存** ✅
   - 添加 `created_by: session.user.id`
   - 集成 SessionManager 认证

3. **UUID 类型错误** ✅
   - 验证 `parent_spec_id` 格式
   - 只保存有效 UUID

4. **部署到错误项目** ✅
   - 记录时文宝鉴项目配置
   - 使用 Dashboard 手动部署避免冲突

### 📊 测试验证

**已测试场景**：
- ✅ 从零开始创建格式
- ✅ 基于系统格式修改
- ✅ AI 优化（两阶段流程）
- ✅ 保存格式到数据库
- ✅ 查看格式列表
- ✅ 查看格式详情
- ✅ 复制格式说明
- ✅ 编辑现有格式
- ✅ 删除自定义格式
- ✅ 搜索和筛选功能

**性能数据**：
- AI 生成文本：3-5秒
- 纯代码解析：1-5ms
- 总提升：~500倍

### 🚀 下一步（阶段 3）

**待实施**：27 个任务（2025-10-20 更新）
- 任务创建流程集成 + 学生端显示：9 个任务
- AI 评分代理 Edge Function：10 个任务
- AI 评分建议界面：8 个任务

**关键变更**（基于与用户讨论）：
- ✅ 引用模式（而非快照）
- ✅ human_input 保存 AI 优化后的文本
- ✅ 移除 assignments.description
- ✅ UI 统一使用「写作要求」

**预计时间**：第二次会话（2025-10-20）

---

**最后更新**：2025-10-20（阶段 3 设计方案最终确认）
**实施者**：AI Assistant + ylzhang@isf.edu.hk

