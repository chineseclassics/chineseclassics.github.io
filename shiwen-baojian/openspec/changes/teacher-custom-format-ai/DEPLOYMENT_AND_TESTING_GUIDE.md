# 阶段 3 部署和测试指南

**版本**：1.0  
**日期**：2025-10-20

---

## 🚀 第一步：部署 grading-agent Edge Function

### 为什么要手动部署？

时文宝鉴使用独立的 Supabase 项目（ID: `fjvgfhdqrezutrmbidds`），而 Supabase CLI 登录的是 story-vocab 项目的账户。为避免冲突，**必须通过 Dashboard 手动部署**。

---

### 部署步骤

#### 1. 复制代码
1. 打开文件：`shiwen-baojian/supabase/functions/grading-agent/index.ts`
2. 全选代码：`Cmd+A`（Mac）或 `Ctrl+A`（Windows）
3. 复制：`Cmd+C` 或 `Ctrl+C`

#### 2. 打开 Supabase Dashboard
1. 访问：https://supabase.com/dashboard
2. 登录账号
3. 选择项目：**shiwen-baojian**（ID: `fjvgfhdqrezutrmbidds`）
4. 项目 URL：https://fjvgfhdqrezutrmbidds.supabase.co

#### 3. 创建 Edge Function
1. 左侧菜单 → **Edge Functions**
2. 点击右上角 **"New Function"** 按钮
3. 输入函数名称：`grading-agent`
4. 粘贴代码：`Cmd+V` 或 `Ctrl+V`

#### 4. 配置环境变量
1. 在函数编辑器下方找到 **"Secrets"** 或 **"Environment Variables"**
2. 添加变量：
   - **变量名**：`DEEPSEEK_API_KEY`
   - **值**：（从现有的 `ai-feedback-agent` 函数复制，或使用您的 DeepSeek API Key）
3. 点击保存

#### 5. 部署函数
1. 点击右上角 **"Deploy"** 按钮
2. 等待部署完成（通常 10-30 秒）
3. 看到绿色 ✅ 表示部署成功

#### 6. 记录函数 URL
部署成功后，记录函数 URL：
```
https://fjvgfhdqrezutrmbidds.supabase.co/functions/v1/grading-agent
```

---

## 🧪 第二步：测试任务创建和写作要求显示

### 测试场景 1：模式 A（系统写作要求）

#### 老师端
1. 登录时文宝鉴（老师账号）
2. 进入某个班级
3. 点击「创建新任务」
4. 填写：
   - 任务标题：「红楼梦人物分析论文」
   - 写作要求：选择「红楼梦论文写作要求」（系统预设）
   - 评分标准：IB MYP 中国古典文学
   - 使用标准：✅ A、✅ B、✅ C、✅ D（全选）
   - 截止日期：设置一个日期
5. 点击「发布任务」

#### 学生端
1. 登录时文宝鉴（学生账号）
2. 进入该班级
3. 点击刚创建的任务
4. **验证**：
   - ✅ 看到任务标题：「红楼梦人物分析论文」
   - ✅ 点击「任务详情」可展开区域
   - ✅ 显示红楼梦论文的自然语言描述（总体要求、结构要求等）
   - ✅ 文字清晰易读（不是 JSON）

---

### 测试场景 2：模式 B/C（自定义写作要求）

#### 老师端 - 创建自定义写作要求
1. 进入「写作要求编辑器」（format-editor.html）
2. 选择「从零开始」或「基于红楼梦论文写作要求」
3. 在 Quill 编辑器中输入：
   ```
   总字数 1800-2000 字
   必须 3 个分论点
   详细分析林黛玉和薛宝钗的外貌描写
   每个人物不少于 300 字
   ```
4. 点击「🤖 AI 优化」
5. **验证**：
   - ✅ 3-5 秒后返回结构化文本
   - ✅ 显示清晰的标题和列表格式
6. 点击「💾 保存写作要求」
7. 输入名称：「张老师红楼梦人物分析 2025」
8. 保存成功

#### 老师端 - 创建任务
1. 点击「创建新任务」
2. 填写：
   - 任务标题：「红楼梦人物外貌分析」
   - 写作要求：选择刚创建的「张老师红楼梦人物分析 2025」
   - 评分标准：IB MYP
   - 使用标准：✅ A、❌ B、✅ C、✅ D（只选 A/C/D）
3. 发布任务

#### 学生端
1. 打开该任务
2. **验证**：
   - ✅ 看到自定义的写作要求（AI 优化后的文本）
   - ✅ 包含具体的内容要求（林黛玉、薛宝钗）

---

### 测试场景 3：引用模式实时生效

#### 老师端 - 修改写作要求
1. 进入「我的写作要求」
2. 找到「张老师红楼梦人物分析 2025」
3. 点击「编辑」
4. 在 Quill 中修改内容（例如改为 4 个分论点）
5. 点击「AI 优化」
6. 保存修改

#### 学生端 - 验证实时生效
1. 刷新任务页面（F5）
2. **验证**：
   - ✅ 看到更新后的写作要求（4 个分论点）
   - ✅ 没有看到旧的要求（3 个分论点）

---

## 🤖 第三步：测试 AI 评分功能

### 前提条件
- ✅ grading-agent Edge Function 已部署
- ✅ 学生已提交完整论文

### 测试步骤

#### 1. 老师打开批改页面
1. 登录老师账号
2. 进入班级 → 任务管理
3. 选择一个已提交的学生论文
4. 点击「批改」

#### 2. 获取 AI 评分建议
1. 在「AI 评分建议」区域点击「獲取 AI 評分建議」
2. **验证加载状态**：
   - ✅ 显示旋转图标
   - ✅ 显示「AI 正在分析論文...」
   - ✅ 显示「預計需要 5-15 秒」
   - ✅ 按钮禁用

3. **验证结果显示**（5-15 秒后）：
   - ✅ 显示总分（例如「20 / 24 分（3 个标准）」，如果只选了 A/C/D）
   - ✅ 显示每个标准的卡片：
     - 标准名称（如「標準 A：分析」）
     - 分数（大号字体）
     - 评分理由（引用论文具体内容）
   - ✅ 只显示任务选中的标准（如果只选了 A/C/D，不显示 B）

#### 3. 采用 AI 建议
1. 点击「採用 AI 建議」
2. **验证**：
   - ✅ 评分表单自动填充分数
   - ✅ 滚动到评分表单
   - ✅ 显示提示消息
3. 手动调整某个分数（例如把 A 从 6 改为 7）
4. 填写总体评语
5. 提交批改

#### 4. 验证保存
1. 刷新页面
2. 再次打开该论文
3. **验证**：
   - ✅ 评分表单显示上次保存的分数
   - ✅ 评语显示正确

---

## 🔒 第四步：测试 RLS 策略

### 测试 1：学生不可见 AI 评分建议

#### 学生端（浏览器开发者工具）
1. 登录学生账号
2. 打开浏览器控制台（F12）
3. 执行以下代码：
```javascript
const { data, error } = await AppState.supabase
  .from('ai_grading_suggestions')
  .select('*');
  
console.log('学生查询结果:', data, error);
```

**预期结果**：
- ✅ `data` 应该为 `[]`（空数组）或 `error` 提示权限不足
- ✅ 学生无法查看任何 AI 评分建议

---

### 测试 2：老师可见 AI 评分建议

#### 老师端（浏览器开发者工具）
1. 登录老师账号
2. 打开浏览器控制台（F12）
3. 执行以下代码：
```javascript
const { data, error } = await AppState.supabase
  .from('ai_grading_suggestions')
  .select('*');
  
console.log('老师查询结果:', data, error);
```

**预期结果**：
- ✅ `data` 应该包含 AI 评分建议记录
- ✅ 老师可以查看自己班级学生的 AI 评分

---

## 📋 测试检查清单

### 任务创建和写作要求显示（3.1.9）
- [ ] 模式 A：系统写作要求 → 学生看到预设自然语言
- [ ] 模式 B/C：自定义写作要求 → 学生看到 AI 优化后的文本
- [ ] 引用模式：老师修改后学生实时看到更新
- [ ] AI 反馈：使用正确的格式规范

### 评分标准多选（3.1.8）
- [ ] 老师可以只选部分标准（如 A/C/D）
- [ ] 前端验证：至少选择 1 个标准
- [ ] AI 评分只针对选中的标准

### AI 评分功能（3.2.10 + 3.3.8）
- [ ] 加载动画正常显示
- [ ] AI 返回评分和理由（5-15 秒）
- [ ] 只显示选中标准的评分
- [ ] 评分理由符合客观性要求（引用论文具体内容）
- [ ] 一键填充功能正常
- [ ] 老师可以手动调整分数
- [ ] 保存到数据库成功

### RLS 策略（3.3.7）
- [ ] 学生不可见 AI 评分建议
- [ ] 老师可见 AI 评分建议
- [ ] 老师只能看到自己班级的 AI 评分

---

## 🐛 常见问题排查

### 问题 1：AI 评分请求失败

**可能原因**：
- Edge Function 未部署
- DEEPSEEK_API_KEY 未配置
- 论文内容为空

**排查步骤**：
1. 打开浏览器控制台查看错误信息
2. 检查 Supabase Dashboard → Edge Functions 状态
3. 验证环境变量配置

---

### 问题 2：学生看不到写作要求

**可能原因**：
- 数据库迁移未执行
- 关联查询失败
- format_spec_id 为 NULL

**排查步骤**：
1. 检查迁移 017 和 018 是否已执行
2. 在 Supabase Dashboard → Table Editor 查看 assignments 表
3. 验证 format_spec_id 字段存在且有值

---

### 问题 3：采用建议不能填充分数

**可能原因**：
- 表单输入框的 name 属性不匹配
- JavaScript 错误

**排查步骤**：
1. 打开浏览器控制台查看错误
2. 检查表单输入框的 name 是否为 `criterion_a`、`criterion_b` 等
3. 验证 AI 返回的 criteriaScores 格式正确

---

## 📊 测试完成标准

**核心功能测试通过**：
- ✅ 三种模式创建任务成功
- ✅ 学生看到正确的写作要求
- ✅ 引用模式实时生效
- ✅ AI 评分功能正常工作
- ✅ 评分标准多选正常
- ✅ RLS 策略正确保护数据

**可选优化**（非必需）：
- 美化 AI 建议卡片样式
- 添加评分历史记录
- 导出评分报告

---

## 🎯 测试完成后

**如果测试通过**：
1. 更新 `tasks.md`：标记所有测试任务为 `- [x]`
2. 在 `STAGE3_IMPLEMENTATION_SUMMARY.md` 记录测试结果
3. 准备投入生产使用

**如果发现问题**：
1. 记录问题详情（截图 + 错误信息）
2. 在控制台查看详细日志
3. 联系 AI 助手协助排查

---

**祝测试顺利！** 🎉

